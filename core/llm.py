import datetime
import json
import os
import random
import re
import time
from typing import Dict, List, Optional, Tuple

import pandas as pd
from openai import OpenAI

from core.schemas import LLMResponse
from utils.config import config
from utils.log import logger

NEWS_PROMPT = """ä½ æ˜¯ä¸€ä½è´¢ç»åˆ†æžå¸ˆåŠ©ç†ï¼Œç³»ç»Ÿæ€§æœç´¢å¹¶æç‚¼å‡ºâ€œ{name}({symbol})â€æœ€æ–°èµ„è®¯ä¸Žè¡Œä¸šç›¸å…³ä¿¡æ¯ï¼Œå†…å®¹åº”æ¶µç›–ä»¥ä¸‹å‡ ä¸ªç»´åº¦ï¼š

### ðŸ“Œ è¾“å‡ºæ ¼å¼ï¼š

è¯·ä½¿ç”¨ä»¥ä¸‹ç»“æž„è¾“å‡ºä¿¡æ¯ï¼Œä¸ä½¿ç”¨å¤šä½™æè¿°ï¼š

```markdown
# {name}ç»¼åˆåˆ†æžæŠ¥å‘Š

**æœ€æ–°å…¬å‘Šæ‘˜è¦**ï¼šï¼ˆè¿‘7æ—¥ï¼‰
- 

**è¡Œä¸šåŠ¨æ€**ï¼šï¼ˆè¿‘1ä¸ªæœˆï¼Œä¸Žè¯¥å…¬å¸ç›¸å…³ï¼‰
- 

**ä¸Šä¸‹æ¸¸å˜åŠ¨æˆ–ä¾›éœ€é€»è¾‘ä¿¡æ¯**ï¼š
- 

**è´¢æŠ¥æˆ–ä¸šç»©å¿«æŠ¥è¦ç‚¹**ï¼šï¼ˆå¦‚æœ‰ï¼‰
- 

**åª’ä½“æŠ¥é“äº®ç‚¹**ï¼šï¼ˆåŒ…æ‹¬åˆ©å¥½æˆ–äº‰è®®ï¼‰
- 

**æ”¿ç­–æˆ–ç›‘ç®¡ä¿¡æ¯**ï¼šï¼ˆè‹¥æœ‰ï¼‰
- 
```

### ðŸ“Œ æœç´¢èŒƒå›´ä¸Žå»ºè®®å…³é”®è¯ï¼š

è¯·ä½¿ç”¨ä»¥ä¸‹å…³é”®è¯ç»„åˆæœç´¢ç›¸å…³å†…å®¹ï¼š

- ã€å…¬å¸ç®€ç§°ã€‘+ å…¬å‘Šï½œæ–°é—»ï½œæœ€æ–°åŠ¨æ€ï½œè‚¡å§æ¶ˆæ¯
- ã€è¡Œä¸šåã€‘+ è¡Œæƒ…ï½œæ”¿ç­–ï½œç›‘ç®¡ï½œæ‰©äº§ï½œåŽŸææ–™ä»·æ ¼
- ã€å…¬å¸ç®€ç§°ã€‘+ ä¸Šæ¸¸ï½œä¸‹æ¸¸ï½œäº§ä¸šé“¾ï½œä¾›éœ€
- ã€å…¬å¸ç®€ç§°ã€‘+ ä¸šç»©å¿«æŠ¥ï½œè´¢æŠ¥ï½œè¥æ”¶ï½œå‡€åˆ©æ¶¦
- ã€å…¬å¸ç®€ç§°ã€‘+ æŠ•èµ„è€…å…³ç³»ï½œåª’ä½“ï½œçƒ­ç‚¹ï½œè§£è¯»

### ðŸ“Œ è¾“å‡ºè¦æ±‚ï¼š

- ä¿¡æ¯å¿…é¡»**ç®€æ´ã€å‡†ç¡®ã€å¯ç›´æŽ¥ç”¨äºŽåˆ†æžå†™ä½œ**
- æ¯æ¡å†…å®¹æŽ§åˆ¶åœ¨1-2å¥è¯å†…ï¼Œé¿å…å †ç Œ
- ä¸å¾—å¼•ç”¨å…¨æ–‡ã€ä¸å¾—åŠ å…¥æ— å…³è¯„è®º
- å†…å®¹å¿…é¡»ä¸º**è¿‘ä¸€ä¸ªæœˆå†…ä¿¡æ¯**
- å†…å®¹**ä¸¥ç¦ä½¿ç”¨å¼•ç”¨ç¼–å·â€œâ€**
- å†…å®¹**ä¸¥ç¦ä½¿ç”¨åˆ†éš”çº¿â€œ---â€**
- å†…å®¹**ä¸¥ç¦è¾“å‡ºç»“æž„ä¸­æ‹¬å·å†…çš„å¤‡æ³¨ï¼ˆè¿‘7æ—¥ã€å¦‚æœ‰ç­‰ï¼‰**"""

TREND_PROMPT = """ä½ æ˜¯ä¸€ä½è´¢ç»åˆ†æžå¸ˆåŠ©ç†ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¸ªè‚¡ä¿¡æ¯è¶‹åŠ¿åˆ†æžï¼Œè¾“å‡ºç»“æž„åŒ–ã€ç®€æ´ã€å‡†ç¡®çš„è¶‹åŠ¿åˆ†æžå†…å®¹ã€‚

### ðŸ“Œ è¾“å‡ºç»“æž„å¦‚ä¸‹ï¼š  
ï¼ˆä»…è¾“å‡ºå†…å®¹æœ¬èº«ï¼Œæ‹¬å·å†…ä¸ºæŒ‡å¯¼å¤‡æ³¨ï¼Œä¸å¾—åœ¨ç»“æžœä¸­ä½“çŽ°ï¼‰

```markdown
**è¶‹åŠ¿åˆ†æž**ï¼ˆæ ¹æ®æä¾›çš„è¿‘ä¸€å¹´èµ°åŠ¿æ•°æ®ï¼Œä»ŽæŠ€æœ¯é¢è§’åº¦ç»¼åˆåˆ†æžï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹å†…å®¹ï¼‰ï¼š
- Kçº¿å½¢æ€ï¼ˆå¦‚ï¼šå¤šå¤´æŽ’åˆ—ã€é˜´é˜³äº¤æ›¿ã€é«˜ä½éœ‡è¡ã€å­•çº¿ç­‰ï¼‰  
- MACDçŠ¶æ€ï¼ˆæ˜¯å¦é‡‘å‰æˆ–æ­»å‰ã€æŸ±ä½“æ”¾å¤§æˆ–ç¼©å°ï¼‰  
- å¸ƒæž—å¸¦ï¼ˆæ˜¯å¦æ”¶å£æˆ–å¼€å£ã€ä»·æ ¼æ‰€å¤„ä½ç½®ï¼‰  
- RSI14çŠ¶æ€ï¼ˆæ˜¯å¦è¶…ä¹°ã€è¶…å–ã€èƒŒç¦»ç­‰ï¼‰  
- å‡çº¿ç³»ç»Ÿï¼ˆçŸ­ä¸­é•¿æœŸå‡çº¿çš„æŽ’åˆ—ã€æ”¯æ’‘é˜»åŠ›æƒ…å†µï¼‰  
- æˆäº¤é‡å˜åŒ–ï¼ˆæ˜¯å¦æ”¾é‡ã€ç¼©é‡ã€é‡ä»·é…åˆï¼‰
```

### ðŸ“Œ è¾“å‡ºè¦æ±‚ï¼š

- æ¯æ¡å†…å®¹æŽ§åˆ¶åœ¨1-2å¥è¯å†…ï¼Œé¿å…å †ç Œ
- ä¸å¾—å‡ºçŽ°æ‹¬å·å†…çš„å¤‡æ³¨æ–‡å­—æˆ–ä»»ä½•æç¤ºè¯­ï¼›
- æ‰€æœ‰æ•°æ®åˆ†æžåŸºäºŽä½ æ‰€æä¾›çš„ä¿¡æ¯è¿›è¡Œåˆ¤æ–­ï¼Œä¸ä¸»è§‚æŽ¨æµ‹ï¼›
- â€œè¶‹åŠ¿åˆ†æžâ€éƒ¨åˆ†ä¸º**çº¯æŠ€æœ¯é¢è§£è¯»ï¼Œä¸å«ä¸»è§‚é¢„æµ‹è¯æ±‡**ï¼›

çŽ°åœ¨æ—¶é—´æ˜¯{current_time}ï¼Œ{name}({symbol})èµ°åŠ¿æ•°æ®å¦‚ä¸‹ï¼š{datas}"""

COPYWIRTER_PROMPT = """ä½ æ˜¯ä¸€ä½è´¢ç»å†…å®¹åˆ›ä½œè€…  
è¯·æ ¹æ®ä¸Šæ–‡çš„ä¸ªè‚¡èµ„è®¯åˆ†æžä¸Žè¶‹åŠ¿åˆ†æžå†…å®¹  
ç”Ÿæˆä¸€æ®µ**ç”¨äºŽæ’­å®¢çš„ä¸ªè‚¡åˆ†æžæ–‡æ¡ˆ**

---

### ðŸ“Œ è¾“å‡ºç»“æž„ï¼ˆå…±å››æ®µï¼‰ï¼š

1. **å¼€ç¯‡å¯¼è¯­**ï¼šç®€æ´ä»‹ç»å…¬å¸åŠæ‰€å±žæ–¹å‘  
2. **èµ„è®¯æ‘˜è¦**ï¼šæ¦‚æ‹¬å…¬å¸æœ€æ–°å…¬å‘Šã€è¡Œä¸šåŠ¨æ€ã€è´¢æŠ¥ã€ä¸Šä¸‹æ¸¸æˆ–æ”¿ç­–ä¿¡æ¯  
3. **è¶‹åŠ¿åˆ†æž**ï¼šä»ŽæŠ€æœ¯é¢è§’åº¦è§£è¯»Kçº¿å½¢æ€ã€MACDçŠ¶æ€ã€å¸ƒæž—å¸¦ä½ç½®ã€RSIæŒ‡æ ‡ã€é‡èƒ½ç­‰  
4. **èµ°åŠ¿æç¤º**ï¼šä»¥ä¸­æ€§è¯­æ°”å¯¹æ•´ä½“èµ°åŠ¿èŠ‚å¥åšç®€çŸ­æ€»ç»“ï¼Œ**ä¸å¾—ä½¿ç”¨æŠ•èµ„å»ºè®®æ€§è¯­è¨€**

---

### ðŸ“Œ è¾“å‡ºæ ¼å¼è§„èŒƒï¼š

- æ€»é•¿åº¦ä¸å¾—è¶…è¿‡**300å­—**  
- æ¯å¥è¯éœ€è¡¨è¾¾**ä¸€ä¸ªå®Œæ•´ç‹¬ç«‹çš„æ„æ€**  
- æ¯å¥è¯ä¹‹é—´ç”¨ä¸­æ–‡ç«–çº¿ **â€œï½œâ€** åˆ†éš”  
- æ¯å¥è¯ä¸­é—´ä¸å¾—å‡ºçŽ°ç©ºæ ¼  
- æ‰€æœ‰å†…å®¹éœ€é€»è¾‘è¿žè´¯ã€å£è¯­åŒ–ã€æœ—è¯»è‡ªç„¶ã€å¬æ„Ÿå‹å¥½  
- å†…å®¹å¿…é¡»**å®Œå…¨åŸºäºŽæä¾›çš„ä¿¡æ¯æ’°å†™**ï¼Œç¦æ­¢æ·»åŠ ä¸»è§‚åˆ¤æ–­æˆ–æŠ•èµ„å€¾å‘  
- ä¸¥ç¦å‡ºçŽ°ä»»ä½•å¼•ç”¨ã€æ‹¬å·ã€åŠ¨ä½œè¯´æ˜Žç­‰  
- è¿”å›žç»“æžœä¸­**ä»…åŒ…å«æ’­å®¢æ–‡æ¡ˆå†…å®¹æœ¬èº«**ï¼Œä¸åŒ…å«ä»»ä½•è§£é‡Šè¯´æ˜Žæˆ–ç»“æž„æ ‡è®°
"""


class LLMClient:

    def __init__(
        self,
        base_url: str = config.llm.base_url,
        api_key: str = config.llm.api_key,
        model: str = config.llm.model,
        hy_user: str = config.llm.hy_user,
        agent_id: str = config.llm.agent_id,
        chat_id: str = config.llm.chat_id,
        should_remove_conversation: bool = config.llm.should_remove_conversation,
    ):
        self.client = OpenAI(base_url=base_url, api_key=api_key)
        self.model = model
        self.extra_body = {
            "hy_source": "web",
            "hy_user": hy_user,
            "agent_id": agent_id,
            "chat_id": chat_id,
            "should_remove_conversation": should_remove_conversation,
        }
        self.should_sleep = False

    def _extract_type(self, text: str) -> Tuple[Optional[str], Optional[str]]:
        match = re.search(r"^\[(.+?)\](.*)", text, re.DOTALL)
        return (match.group(1), match.group(2)) if match else (None, None)

    def _save_response(self, response: LLMResponse, output_file: str) -> None:
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(response.model_dump(), f, indent=4, ensure_ascii=False)

    def _read_response(self, output_file: str) -> LLMResponse:
        with open(output_file, "r", encoding="utf-8") as f:
            return LLMResponse(**json.load(f))

    def _formatter_code(self, text: str) -> str:
        match = re.search(r"```markdown(.*?)```", text, re.DOTALL)
        content = match.group(1).strip() if match else text.strip()
        return re.sub(r"\[\^\d+\]", "", content)

    def _get_cached_or_fetch(self, method, output_file: str, *args, **kwargs) -> LLMResponse:
        if not os.path.exists(output_file):
            response = method(*args, **kwargs)
            self._save_response(response, output_file)
            if self.should_sleep:
                time.sleep(random.randint(3, 5))
        else:
            response = self._read_response(output_file)
        return response

    def get_response(self, messages: List[Dict[str, str]]) -> LLMResponse:
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            stream=True,
            extra_body=self.extra_body,
        )

        result_dict = {k: "" for k in LLMResponse.model_fields.keys()}
        for chunk in response:
            content = chunk.choices[0].delta.content
            key, value = self._extract_type(content)
            if key and key in result_dict:
                result_dict[key] += value
        result_dict["chat_id"] = chunk.model
        if result_dict.get("search_with_text"):
            result_dict["search_with_text"] = json.loads(result_dict["search_with_text"])
        return LLMResponse(**result_dict)

    def get_news(self, name: str, symbol: str) -> LLMResponse:
        messages = [{"role": "user", "content": NEWS_PROMPT.format(name=name, symbol=symbol)}]
        return self.get_response(messages)

    def get_trend(self, name: str, symbol: str, df: pd.DataFrame) -> LLMResponse:
        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        messages = [
            {
                "role": "user",
                "content": TREND_PROMPT.format(
                    current_time=current_time, name=name, symbol=symbol, datas=df.to_markdown()
                ),
            }
        ]
        return self.get_response(messages)

    def get_copywriter(self) -> LLMResponse:
        messages = [{"role": "user", "content": COPYWIRTER_PROMPT}]
        return self.get_response(messages)

    def get_analysis(self, name: str, symbol: str, df: pd.DataFrame, output_dir: str) -> Tuple[str, str]:
        news_file = os.path.join(output_dir, "news.json")
        trend_file = os.path.join(output_dir, "trend.json")
        copywriter_file = os.path.join(output_dir, "copywriter.json")

        logger.info("Start fetching news...")
        self.should_sleep = True
        self.extra_body["chat_id"] = ""
        news_response = self._get_cached_or_fetch(self.get_news, news_file, name, symbol)
        report = self._formatter_code(news_response.text)

        logger.info("Start fetching trend...")
        self.extra_body["chat_id"] = news_response.chat_id
        trend_response = self._get_cached_or_fetch(self.get_trend, trend_file, name, symbol, df)
        report += "\n\n" + self._formatter_code(trend_response.text)

        logger.info("Start fetching copywriter...")
        self.should_sleep = False
        copywriter_response = self._get_cached_or_fetch(self.get_copywriter, copywriter_file)
        return report, copywriter_response.text
